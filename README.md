# 基于DQN强化深度学习的五子棋博弈AI
---
作者：韩昊轩

时间：2023年五月

Currently, using DQN2 as Learning algorithm and GomokuAI3 as Network model.

### 按时间线排序的失败

1. 输入棋盘状态未进行分割，导致无法收敛，已改正
2. 探索率折损过高，导致陷入局部最优，已改正
3. DQN算法缺陷，已改正
4. 学习率过高，出现过拟合现象，已改正
5. 网络结构过小，出现Loss下降顺利但模型效果不好，已改正
6. 奖励系数过高，导致模型过于期望未来价值，忽视短期价值，于短平快的五子棋特性不符，已改正
7. 网络可以在小规模4x4-3上表现良好，但在8x8棋盘上表现不佳，通过改进奖励机制，引入更多先验知识后解决

### 优化方向

1. 放弃无先验知识的环境，会导致奖励稀疏，网络学习效果不好
2. 优化卷积神经网络结构
3. 调整epsilon随机落子算法
4. 优化动作选择遮罩，引入更多先验知识，限制AI落子

###   